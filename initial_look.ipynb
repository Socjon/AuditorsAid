{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TOP'></a>\n",
    "\n",
    "### Data cleaning\n",
    "[Exploring]\n",
    "### Models\n",
    "[Train Test Split](#TTS)  \n",
    "[Decision Tree](#clf_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('BusinessMasterFile.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.REVENUE_AMT.value_counts()[:5])\n",
    "df.REVENUE_AMT.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.ASSET_AMT.value_counts()[:5])\n",
    "print(df.ASSET_AMT.isna().sum())\n",
    "print(df.ASSET_CD.value_counts()[:5])\n",
    "print(df.ASSET_CD.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am trying to decide whether or not to drop ASSEST_CD/ASSET_AMT and INCOME_AMT/INCOME_CD.\n",
    "\n",
    "ASSET_AMT is continious data, rather than the coded data in ASSET_CD, so I will keep the AMTs reported over the prebinned. I can alter it myself if need be. Also there seems to be some discrepancy in values from the coded and the reported, which makes my decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "- Combine `city`, `street`, `state` into lat and longs. Drop `city`, `street`, `state`. This is the location of the headquarters and doesn't mean that the 501c has operations in that state. https://github.com/geopy/geopy\n",
    "- Change datetime data into correct formats. `TAX_PERIOD`, `RULING_DATE`\n",
    "- Make things categorical\n",
    "- Investigate any connection between SORT_NAME and GROUP EXEMPTION NUM and AFFILCATION CODE [Connection?](#task1)\n",
    "- Check the Ruling year after 1995 and see if any NTEE exisits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"task1\"></a>\n",
    "\n",
    "Sort Name Line is another name under which the organization does business.  Also used for trade names, chapter names, or local numbers for subordinate organizations of group rulings\n",
    "\n",
    "Central - This code is used if the organization is a central type organization (no group exemption) of a National, Regional or Geographic grouping of organizations. 2 Intermediate - This code is used if the organization is an intermediate organization (no group exemption) of a National, Regional or Geographic grouping of organizations (such as a state headquarters of a national organization). 3 Independent - This code is used if the organization is an independent organization or an independent auxiliary \n",
    "(i.e., not affiliated with a National, Regional, or Geographic grouping of organizations). 6 Central - This code is used if the organization is a parent (group ruling) and is not a church or 501(c)(1) organization. 7 Intermediate - This code is used if the organization is a group exemption intermediate organization of a National, Regional or Geographic grouping of organizations. 8 Central - This code is used if the organization is a parent (group ruling) and is a church or 501(c)(1) organization. 9 Subordinate - This code is used if the organization is a subordinate in a group ruling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ICO', \n",
    "         'RULING', \n",
    "         'ACT2', \n",
    "         'ACT3', \n",
    "         'ASSET_CD', \n",
    "         'INCOME_CD', \n",
    "         'LEVEL4', \n",
    "         'TAX_PERIOD'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear pattern of missing values from `ASSET_AMT`,`INCOME_AMT`, and `REVENUE_AMT`. I will drop values from one column, extending down the rows and then will recheck the patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['ASSET_AMT'])\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~370,000 entries were removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 100K from `REVENUE_AMT` will be dropped as well. I will combine the `SORT_NAME` column with the `NAME` column since they both come from the same field, just a different line. `NTEE_CD` will be addressed seperately as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['REVENUE_AMT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SORT_NAME = df.SORT_NAME.fillna(value = '') #Replaces np.NaN values with something else, string + np.NaN = np.NaN\n",
    "df['NAME_FULL'] = df.NAME + ' ' + df.SORT_NAME #New column\n",
    "df.drop(['NAME', 'SORT_NAME'], axis=1, inplace=True) #Getting rid of the old\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My target is going to `ACTIVITY`/`NTEE_CD`. The values in `ACTIVITY` are 9 characters long, each set of three indicating what kind of the organization it is There are some that needed more than one set of three to define their organization, others only have one. Planning to use only the first activity code. Also I have to keep in mind, there are ones that could apply to different targets. As expected, the data itself is not that clean. Effort will be made to tidy it up.\n",
    "\n",
    "The NTEE_CD code was introduced to replace the three digit code after **(CHECK if not 1994/1996)** tax year 1995. I will make my own mapping from the old system to the new system.  \n",
    "\n",
    "I will run three models; a pre-1995 target, post-1995 target, and the entire dataset with a semi-converted target. The mapping that I create will is an area of potential error. This is a place of further improvement on future iterations of this project. \n",
    "\n",
    "Lets now grab some quick masks on the smaller subsets to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post = df\n",
    "post_index = df_post.NTEE_CD.notna() #mask for all the non-profits with the new coding\n",
    "\n",
    "post_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.RULEYEAR[post_index].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. **ASK JEFF ABOUT THIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.NTEE_CD.notna()) & (df.ACTIVITY == 0)].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NTEE_CD.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NTEE_CD.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ACTIVITY.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is something wrong with the above `.value_counts()`. The Activity Codes provided by the IRS have leading zeroes. Since there wasn't an attempt to control for it them when orginally reading the files, I want further to investigate if the `ACTIVITY` lines contain 9 characters. If they don't, I will adjust them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.ACTIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "for x in temp:\n",
    "    length.append(len(str(x)))\n",
    "pd.Series(length).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, adjustments are need. Make a small function that will adjust the `ACTIVITY` input to match the 9 character length expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_len(num):\n",
    "    string = str(num)\n",
    "    \n",
    "    if len(string) >= 7:\n",
    "        \n",
    "        if len(string) == 9:\n",
    "            return int(string[0:3])\n",
    "        if len(string) == 8:\n",
    "            return int(string[0:2])\n",
    "        if len(string) == 7:\n",
    "            return int(string[0:1])\n",
    "    else:\n",
    "        return num\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_len(123456789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester set for a encoding that I will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = df.loc[(df.NTEE_CD.isna()) & (df.ACTIVITY != 0)][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_NTEE_V1(y):\n",
    "    \n",
    "    x = adj_len(y)\n",
    "    \n",
    "    list_a =list(range(60,120))\n",
    "    list_b =list(range(30,60)) + [540, 914]\n",
    "    list_c =list(range(350,380)) + [529]\n",
    "    list_d =[913]\n",
    "    list_e =list(range(150,180)) + [531] + list(range(541,544))\n",
    "    list_f = []\n",
    "    list_g = []\n",
    "    list_h = []\n",
    "    list_i =list(range(460,466)) + [406, 526, 527, 528]\n",
    "    list_j =list(range(120,150)) + list(range(200,230)) + [920]\n",
    "    list_k =list(range(230,250)) + [916]\n",
    "    list_l =list(range(380,400)) + [401]\n",
    "    list_m =[902]\n",
    "    list_n =list(range(280,320))\n",
    "    list_o =list(range(320,350))\n",
    "    list_p =list(range(563,576)) + [917, 918]\n",
    "    list_q =list(range(510,514)) + [518, 519, 520, 522, 910, 911, 912]\n",
    "    list_r =list(range(430,450)) + list(range(480,510)) + [261, 405, 481, 482, 534, 535, 924]\n",
    "    list_s =list(range(408,430)) + [404, 524, 533, 903, 919, 921]\n",
    "    list_t =list(range(600,604)) + list(range(560,563))\n",
    "    list_u =list(range(180,200)) \n",
    "    list_v = []\n",
    "    list_w =list(range(250,253)) + list(range(536,540)) + list(range(905,909)) + [262, 263, 400, 402, 403, 407, 514, 515, 516, 521, 523, 525, 530 , 532, 559, 915]\n",
    "    list_x =list(range(1,30)) + [517]\n",
    "    list_y =list(range(264,280)) + [253, 254, 259, 260, 900, 901, 922]\n",
    "    list_z = []\n",
    "\n",
    "    if x in list_a:\n",
    "        return 'A'\n",
    "    if x in list_b:\n",
    "        return 'B'\n",
    "    if x in list_c:\n",
    "        return 'C'\n",
    "    if x in list_d:\n",
    "        return 'D'\n",
    "    if x in list_e:\n",
    "        return 'E'\n",
    "    if x in list_f:\n",
    "        return 'F'\n",
    "    if x in list_g:\n",
    "        return 'G'\n",
    "    if x in list_h:\n",
    "        return 'H'\n",
    "    if x in list_i:\n",
    "        return 'I'\n",
    "    if x in list_j:\n",
    "        return 'J'\n",
    "    if x in list_k:\n",
    "        return 'K'\n",
    "    if x in list_l:\n",
    "        return 'L' \n",
    "    if x in list_m:\n",
    "        return 'M'\n",
    "    if x in list_n:\n",
    "        return 'N'\n",
    "    if x in list_o:\n",
    "        return 'O'\n",
    "    if x in list_p:\n",
    "        return 'P'\n",
    "    if x in list_q:\n",
    "        return 'Q'\n",
    "    if x in list_r:\n",
    "        return 'R'\n",
    "    if x in list_s:\n",
    "        return 'S'\n",
    "    if x in list_t:\n",
    "        return 'T'\n",
    "    if x in list_u:\n",
    "        return 'U'\n",
    "    if x in list_v:\n",
    "        return 'V'\n",
    "    if x in list_w:\n",
    "        return 'W'\n",
    "    if x in list_x:\n",
    "        return 'X'\n",
    "    if x in list_y:\n",
    "        return 'Y'\n",
    "    if x in list_z:\n",
    "        return 'Z'\n",
    "    else:\n",
    "        trouble.append(x)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(code_NTEE_V1(205000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test something with a leading zero, or an `ACTIVITY` that does not have 9 characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trouble = [] #Within my small data set, any codes that don't have a new label\n",
    "small.ACT1.apply(code_NTEE_V1)\n",
    "print(set(trouble))\n",
    "print(len(trouble))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the quick check, there are codes that were not coded. This was to be expected. Within the set above, none of these are defined by the IRS. I suspect this set to grown once applied to the larger dataset.  \n",
    "\n",
    "Within the process, I will update the master list with proper categorizations through out. The mapping will be adjusted accordingly. Please see the documentation if further review is [desired](./irs_jan_2010.pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small.NTEE_CD = small.ACT1.apply(code_NTEE_V1)\n",
    "small.NTEE_CD.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When updating the new column, columns that don't have a mapping will be updated to be a `None` value that will be later removed.\n",
    "\n",
    "Lets take care of the subset of rows that can not have any targets for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NTEE_CD.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[(df.NTEE_CD.isna()) & (df.ACT1 == 0)].shape)\n",
    "df[(df.NTEE_CD.isna()) & (df.ACT1 == 0)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = df.shape\n",
    "\n",
    "mask = df.index[(df.NTEE_CD.isna()) & (df.ACT1 == 0)] #index numbers to drop\n",
    "df = df.drop(mask)\n",
    "\n",
    "after = df.shape\n",
    "\n",
    "print(f'From {before} rows, down to {after} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trouble = [] #the code_NTEE(X) function has a list to check the missing variables\n",
    "look = df.ACTIVITY.apply(code_NTEE_V1)\n",
    "set(trouble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I manually went back and updated my `code_NTEE` function. I updated lists and created a new list for undefined codes. Also, there were a few ambigious codings that I have decided to drop altogeter. These includes definitions such as \"Indians (tribes, cultures, etc.)\" , \"Government instrumentality or agency\", and \"947(a)(2) trust\". Further man hours are required to shift through the material to categorize them correctly.  \n",
    "\n",
    "Using the updated `code_NTEE` function below, I will move forward with the data cleaning process. https://nccs.urban.org/publication/irs-activity-codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_NTEE_V2(y):\n",
    "    \n",
    "    x = adj_len(y)\n",
    "    \n",
    "    list_a =list(range(60,120))\n",
    "    list_b =list(range(30,60)) + [540, 914]\n",
    "    list_c =list(range(350,380)) + [529]\n",
    "    list_d =[913]\n",
    "    list_e =list(range(150,180)) + [531] + list(range(541,544))\n",
    "    list_f = []\n",
    "    list_g = []\n",
    "    list_h = []\n",
    "    list_i =list(range(460,466)) + [406, 526, 527, 528]\n",
    "    list_j =list(range(120,150)) + list(range(200,230)) + [920]\n",
    "    list_k =list(range(230,250)) + [916]\n",
    "    list_l =list(range(380,400)) + [401]\n",
    "    list_m =[902]\n",
    "    list_n =list(range(280,320))\n",
    "    list_o =list(range(320,350))\n",
    "    list_p =list(range(563,576)) + [917, 918]\n",
    "    list_q =list(range(510,514)) + [518, 519, 520, 522, 910, 911, 912]\n",
    "    list_r =list(range(430,450)) + list(range(480,510)) + [261, 405, 481, 482, 534, 535, 924]\n",
    "    list_s =list(range(408,430)) + [404, 524, 533, 903, 919, 921]\n",
    "    list_t =list(range(600,604)) + list(range(560,563))\n",
    "    list_u =list(range(180,200)) \n",
    "    list_v = []\n",
    "    list_w =list(range(250,253)) + list(range(536,540)) + list(range(905,909)) + [262, 263, 400, 402, 403, 407, 514, 515, 516, 521, 523, 525, 530 , 532, 559, 915]\n",
    "    list_x =list(range(1,30)) + [517]\n",
    "    list_y =list(range(264,280)) + [253, 254, 259, 260, 900, 901, 922]\n",
    "    list_z = []\n",
    "    \n",
    "    too_vague = [904, 909, 923] + list(range(925,999))\n",
    "    not_defined = [256, 257, 466,469, 470, 556, 557, 999] + list(range(450,460)) + list(range(484, 509)) + list(range(576, 600)) + list(range(603,900)) + too_vague\n",
    "\n",
    "    if x == 0:\n",
    "        return None\n",
    "    if x in list_a:\n",
    "        return 'A'\n",
    "    if x in list_b:\n",
    "        return 'B'\n",
    "    if x in list_c:\n",
    "        return 'C'\n",
    "    if x in list_d:\n",
    "        return 'D'\n",
    "    if x in list_e:\n",
    "        return 'E'\n",
    "    if x in list_f:\n",
    "        return 'F'\n",
    "    if x in list_g:\n",
    "        return 'G'\n",
    "    if x in list_h:\n",
    "        return 'H'\n",
    "    if x in list_i:\n",
    "        return 'I'\n",
    "    if x in list_j:\n",
    "        return 'J'\n",
    "    if x in list_k:\n",
    "        return 'K'\n",
    "    if x in list_l:\n",
    "        return 'L' \n",
    "    if x in list_m:\n",
    "        return 'M'\n",
    "    if x in list_n:\n",
    "        return 'N'\n",
    "    if x in list_o:\n",
    "        return 'O'\n",
    "    if x in list_p:\n",
    "        return 'P'\n",
    "    if x in list_q:\n",
    "        return 'Q'\n",
    "    if x in list_r:\n",
    "        return 'R'\n",
    "    if x in list_s:\n",
    "        return 'S'\n",
    "    if x in list_t:\n",
    "        return 'T'\n",
    "    if x in list_u:\n",
    "        return 'U'\n",
    "    if x in list_v:\n",
    "        return 'V'\n",
    "    if x in list_w:\n",
    "        return 'W'\n",
    "    if x in list_x:\n",
    "        return 'X'\n",
    "    if x in list_y:\n",
    "        return 'Y'\n",
    "    if x in list_z:\n",
    "        return 'Z'\n",
    "    if x in not_defined:\n",
    "        return None\n",
    "    else:\n",
    "        trouble.append(x)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trouble = [] #the code_NTEE(X) function has a list to check the missing variables\n",
    "look = df.ACTIVITY.apply(code_NTEE_V2)\n",
    "trouble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no trouble codes anymore. We will merge the changes and tidy up the last few things wrong with the data.\n",
    "Keep in mind that this step heavily effects the target outcome in the joint dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NTEE_CD.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NTEE_CD.fillna(df.ACTIVITY.apply(code_NTEE_V2), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.NTEE_CD.isna().sum())\n",
    "df[df.NTEE_CD.isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally dropping the remaining ~11K rows that don't have a clear NTEE code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['NTEE_CD'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to drop the very small subset of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['STATE', 'STREET'], inplace=True) #dropping the missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now taking a look at `NTEE_CD` column and getting the proper format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NTEE_CD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets remove the more specific coding form the `NTEE` column, just leaving the one of the 26 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NTEE_CD = df.NTEE_CD.apply(lambda x: x[0:1])\n",
    "df.NTEE_CD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ZIP = df.ZIP.apply(lambda x: str(x)[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets drop the last few rows that won't be used and change the date types for the columns that need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not forgetting we have subsets of our data, grabbing the masks we created before cleaning the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = df_post.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post = df[df.index.isin(post)]\n",
    "\n",
    "target_post = pd.DataFrame(df_post.NTEE_CD)\n",
    "data_post = df_post.drop(['NTEE_CD', 'NAME_FULL', 'STREET', 'ZIP', 'CITY','ACTIVITY', 'EIN', 'ACT1', 'ACCT_PD'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_post.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_full = pd.DataFrame(df.NTEE_CD)\n",
    "data_full = df.drop(['NTEE_CD', 'NAME_FULL', 'STREET', 'ZIP', 'CITY','ACTIVITY', 'EIN', 'ACT1', 'ACCT_PD'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.info(), target_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## MODELS \n",
    "\n",
    "Decision Tree<a id=\"clf_DT\"></a>  \n",
    "[TOP](#TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn import tree \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training sets <a id='TTS'></a>  \n",
    "[TOP](#TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum_post = pd.get_dummies(data_post, columns=['STATE', 'GROUP', 'SUBSECTION', 'AFFILIATION', \n",
    "                                       'CLASSIFICATION', 'DEDUCTIBILITY', 'FOUNDATION', \n",
    "                                       'ORGANIZATION', 'STATUS', 'FILING_REQ_CD', \n",
    "                                       'PF_FILING_REQ_CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_post, X_test_post, y_train_post, y_test_post = train_test_split(df_dum_post, target_post, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_post.to_pickle('X_train_post')\n",
    "X_test_post.to_pickle('X_test_post')\n",
    "y_train_post.to_pickle('y_train_post')\n",
    "y_test_post.to_pickle('y_test_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train_post = pd.read_pickle('X_train_post')\n",
    "y_train_post = pd.read_pickle('y_train_post')\n",
    "X_test_post = pd.read_pickle('X_test_post')\n",
    "y_test_post = pd.read_pickle('y_test_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_post.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum_full = pd.get_dummies(data_full, columns=['STATE', 'GROUP', 'SUBSECTION', 'AFFILIATION', \n",
    "                                       'CLASSIFICATION', 'DEDUCTIBILITY', 'FOUNDATION', \n",
    "                                       'ORGANIZATION', 'STATUS', 'FILING_REQ_CD', \n",
    "                                       'PF_FILING_REQ_CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(df_dum_full, target_full, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.to_pickle('X_train_full')\n",
    "X_test_full.to_pickle('X_test_full')\n",
    "y_train_full.to_pickle('y_train_full')\n",
    "y_test_full.to_pickle('y_test_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train_full = pd.read_pickle('X_train_full')\n",
    "y_train_full = pd.read_pickle('y_train_full')\n",
    "X_test_full = pd.read_pickle('X_test_full')\n",
    "y_test_full = pd.read_pickle('y_test_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn import tree \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import time\n",
    "\n",
    "clf_DT = DecisionTreeClassifier(max_features='auto', max_depth=10, min_samples_split=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "clf_DT.fit(X_train_full, y_train_full)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_post.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf_DT.predict(X_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test_full,y_hat) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "fig, ax = plt.subplots(figsize=(18,12)) #Making the final out put a bit more readable than the standard\n",
    "cm = ConfusionMatrix(clf_DT, ax=ax) #This instance takes in an axes to add to a exisiting figure.\n",
    "\n",
    "cm.score(X_test_full, y_test_full)\n",
    "\n",
    "# How did we do?\n",
    "cm.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.NTEE_CD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.NTEE_CD.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My classes are imbalanced. I forgot to review my target variables to ensure they were correct. BUT I got ~20% accuracy, which makes sense since that is my biggest class. This is a baseline, even a very rough one. There were a few classes where most everything ended up, which is intriguing within itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal = ['c', '0', '8'] #Setting what we don't want\n",
    "mask = df_full[df_full.NTEE_CD.isin(removal)] #Finding the rows that contain those values and masking a mask\n",
    "df_full = df_full.drop(mask.index) #Dropping based on index\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to check the top 5 percentages of the groups within all my columns. I want to understand why B and P were such popular columns. Also how weighted my classes may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.NT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
